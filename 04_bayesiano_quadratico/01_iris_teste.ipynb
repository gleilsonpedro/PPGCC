{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.9644444444444444\n",
      "Standard Deviation of Accuracy: 0.028458329944145988\n",
      "Best Confusion Matrix:\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 0 34 11]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_iris_data():\n",
    "    # Carregar os dados do conjunto de dados iris\n",
    "   \n",
    "    from sklearn.datasets import load_iris\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "    return X, y\n",
    "\n",
    "def shuffle_data(X, y, random_state=None):\n",
    "    # Embaralhar os dados mantendo a correspondência entre features e rótulos\n",
    "    \n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    indices = np.random.permutation(len(X))\n",
    "    return X[indices], y[indices]\n",
    "\n",
    "def split_data(X, y, test_size=0.3):\n",
    "    # Dividir os dados em conjuntos de treinamento e teste\n",
    "    split_index = int(len(X) * (1 - test_size))\n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def calculate_means(X_train, y_train):\n",
    "    # Calcular as médias de cada classe\n",
    "    unique_classes = np.unique(y_train)\n",
    "    class_means = []\n",
    "    for cls in unique_classes:\n",
    "        class_means.append(np.mean(X_train[y_train == cls], axis=0))\n",
    "    return class_means\n",
    "\n",
    "def calculate_covariance_matrices(X_train, y_train, means):\n",
    "    # Calcular as matrizes de covariância de cada classe\n",
    "    unique_classes = np.unique(y_train)\n",
    "    cov_matrices = []\n",
    "    for cls, mean in zip(unique_classes, means):\n",
    "        cov_matrix = np.cov(X_train[y_train == cls], rowvar=False)\n",
    "        cov_matrices.append(cov_matrix)\n",
    "    return cov_matrices\n",
    "\n",
    "def gaussian_pdf(x, mean, cov):\n",
    "    # Função de densidade de probabilidade gaussiana multivariada\n",
    "    n = len(x)\n",
    "    exp_term = np.exp(-0.5 * np.dot(np.dot((x - mean).T, np.linalg.inv(cov)), (x - mean)))\n",
    "    coef = 1 / ((2 * np.pi) ** (n / 2) * np.linalg.det(cov) ** 0.5)\n",
    "    return coef * exp_term\n",
    "\n",
    "def predict_class(X_test, class_means, cov_matrices):\n",
    "    # Predição da classe para cada amostra no conjunto de teste\n",
    "    y_pred = []\n",
    "    for x in X_test:\n",
    "        probabilities = []\n",
    "        for mean, cov in zip(class_means, cov_matrices):\n",
    "            probabilities.append(gaussian_pdf(x, mean, cov))\n",
    "        y_pred.append(np.argmax(probabilities))\n",
    "    return np.array(y_pred)\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    # Calcular a acurácia\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def confusion_matrix(y_true, y_pred, num_classes):\n",
    "    # Calcular a matriz de confusão\n",
    "    conf_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        conf_matrix[true][pred] += 1\n",
    "    return conf_matrix\n",
    "\n",
    "def holdout_experiment(X, y, n_runs=20, test_size=0.3):\n",
    "    accuracies = []\n",
    "\n",
    "    for _ in range(n_runs):\n",
    "        # Embaralhar e dividir os dados\n",
    "        X_shuffled, y_shuffled = shuffle_data(X, y, random_state=_)\n",
    "        X_train, X_test, y_train, y_test = split_data(X_shuffled, y_shuffled, test_size=test_size)\n",
    "\n",
    "        # Calcular as médias e as matrizes de covariância de cada classe\n",
    "        class_means = calculate_means(X_train, y_train)\n",
    "        cov_matrices = calculate_covariance_matrices(X_train, y_train, class_means)\n",
    "\n",
    "        # Realizar a predição\n",
    "        y_pred = predict_class(X_test, class_means, cov_matrices)\n",
    "\n",
    "        # Calcular a acurácia e armazenar\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    accuracies = np.array(accuracies)\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "    best_index = np.argmax(accuracies)\n",
    "\n",
    "    # Calcular a matriz de confusão da melhor realização\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, test_size=test_size)\n",
    "    class_means = calculate_means(X_train, y_train)\n",
    "    cov_matrices = calculate_covariance_matrices(X_train, y_train, class_means)\n",
    "    y_pred = predict_class(X_test, class_means, cov_matrices)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred, len(np.unique(y)))\n",
    "\n",
    "    return mean_accuracy, std_accuracy, conf_matrix\n",
    "\n",
    "# Carregar os dados iris\n",
    "X, y = load_iris_data()\n",
    "\n",
    "# Executar o experimento holdout\n",
    "mean_accuracy, std_accuracy, best_conf_matrix = holdout_experiment(X, y)\n",
    "\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n",
    "print(\"Standard Deviation of Accuracy:\", std_accuracy)\n",
    "print(\"Best Confusion Matrix:\")\n",
    "print(best_conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.9644444444444444\n",
      "Standard Deviation of Accuracy: 0.028458329944145988\n",
      "Best Confusion Matrix:\n",
      "[[ 0  0  0]\n",
      " [ 0  0  0]\n",
      " [ 0 34 11]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_iris_data():\n",
    "    from sklearn.datasets import load_iris\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "    return X, y\n",
    "\n",
    "def shuffle_data(X, y, random_state=None):\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "    indices = np.random.permutation(len(X))\n",
    "    return X[indices], y[indices]\n",
    "\n",
    "def split_data(X, y, test_size=0.3):\n",
    "    split_index = int(len(X) * (1 - test_size))\n",
    "    X_train, X_test = X[:split_index], X[split_index:]\n",
    "    y_train, y_test = y[:split_index], y[split_index:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def calculate_means(X_train, y_train):\n",
    "    unique_classes = np.unique(y_train)\n",
    "    class_means = []\n",
    "    for cls in unique_classes:\n",
    "        class_means.append(np.mean(X_train[y_train == cls], axis=0))\n",
    "    return class_means\n",
    "\n",
    "def calculate_covariance_matrices(X_train, y_train, means):\n",
    "    unique_classes = np.unique(y_train)\n",
    "    cov_matrices = []\n",
    "    for cls, mean in zip(unique_classes, means):\n",
    "        cov_matrix = np.cov(X_train[y_train == cls], rowvar=False)\n",
    "        cov_matrices.append(cov_matrix)\n",
    "    return cov_matrices\n",
    "\n",
    "def gaussian_pdf(x, mean, cov):\n",
    "    n = len(x)\n",
    "    exp_term = np.exp(-0.5 * np.dot(np.dot((x - mean).T, np.linalg.inv(cov)), (x - mean)))\n",
    "    coef = 1 / ((2 * np.pi) ** (n / 2) * np.linalg.det(cov) ** 0.5)\n",
    "    return coef * exp_term\n",
    "\n",
    "def predict_class(X_test, class_means, cov_matrices):\n",
    "    y_pred = []\n",
    "    for x in X_test:\n",
    "        probabilities = []\n",
    "        for mean, cov in zip(class_means, cov_matrices):\n",
    "            probabilities.append(gaussian_pdf(x, mean, cov))\n",
    "        y_pred.append(np.argmax(probabilities))\n",
    "    return np.array(y_pred)\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def confusion_matrix(y_true, y_pred, num_classes):\n",
    "    conf_matrix = np.zeros((num_classes, num_classes), dtype=int)\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        conf_matrix[true, pred] += 1\n",
    "    return conf_matrix\n",
    "\n",
    "def holdout_experiment(X, y, n_runs=20, test_size=0.3):\n",
    "    accuracies = []\n",
    "\n",
    "    for _ in range(n_runs):\n",
    "        X_shuffled, y_shuffled = shuffle_data(X, y, random_state=_)\n",
    "        X_train, X_test, y_train, y_test = split_data(X_shuffled, y_shuffled, test_size=test_size)\n",
    "\n",
    "        class_means = calculate_means(X_train, y_train)\n",
    "        cov_matrices = calculate_covariance_matrices(X_train, y_train, class_means)\n",
    "\n",
    "        y_pred = predict_class(X_test, class_means, cov_matrices)\n",
    "\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    accuracies = np.array(accuracies)\n",
    "    mean_accuracy = np.mean(accuracies)\n",
    "    std_accuracy = np.std(accuracies)\n",
    "    best_index = np.argmax(accuracies)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_data(X, y, test_size=test_size)\n",
    "    class_means = calculate_means(X_train, y_train)\n",
    "    cov_matrices = calculate_covariance_matrices(X_train, y_train, class_means)\n",
    "    y_pred = predict_class(X_test, class_means, cov_matrices)\n",
    "    \n",
    "    # Calcular a matriz de confusão manualmente\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred, num_classes=len(np.unique(y)))\n",
    "\n",
    "    return mean_accuracy, std_accuracy, conf_matrix\n",
    "\n",
    "X, y = load_iris_data()\n",
    "mean_accuracy, std_accuracy, best_conf_matrix = holdout_experiment(X, y)\n",
    "\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n",
    "print(\"Standard Deviation of Accuracy:\", std_accuracy)\n",
    "print(\"Best Confusion Matrix:\")\n",
    "print(best_conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.35\n",
      "Standard Deviation of Accuracy: 0.060092521257733164\n",
      "Best Confusion Matrix:\n",
      "[[2 3 2]\n",
      " [1 6 3]\n",
      " [2 6 5]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Carregar o conjunto de dados Iris\n",
    "def load_iris_dataset():\n",
    "    from sklearn.datasets import load_iris\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "    return X, y\n",
    "\n",
    "# Função para dividir os dados em conjunto de treinamento e teste\n",
    "def train_test_split_custom(X, y, test_size=0.2):\n",
    "    n_samples = X.shape[0]\n",
    "    n_test = int(n_samples * test_size)\n",
    "    indices = np.arange(n_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    X_shuffled = X[indices]\n",
    "    y_shuffled = y[indices]\n",
    "    X_train = X_shuffled[:-n_test]\n",
    "    X_test = X_shuffled[-n_test:]\n",
    "    y_train = y_shuffled[:-n_test]\n",
    "    y_test = y_shuffled[-n_test:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Modelo de classificação (substitua esta parte pelo seu modelo)\n",
    "class Model:\n",
    "    def fit(self, X_train, y_train):\n",
    "        pass\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return np.random.randint(low=0, high=3, size=X_test.shape[0])\n",
    "\n",
    "model = Model()\n",
    "\n",
    "# Listas para armazenar os resultados\n",
    "accuracies = []\n",
    "confusion_matrices = []\n",
    "\n",
    "# Iteração do experimento holdout\n",
    "for _ in range(10):\n",
    "    # Carregar o conjunto de dados Iris\n",
    "    X, y = load_iris_dataset()\n",
    "    \n",
    "    # Dividir os dados em conjunto de treinamento e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split_custom(X, y, test_size=0.2)\n",
    "    \n",
    "    # Treinar o modelo\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Prever os rótulos para o conjunto de teste\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calcular a precisão\n",
    "    correct_predictions = np.sum(y_pred == y_test)\n",
    "    accuracy = correct_predictions / len(y_test)\n",
    "    \n",
    "    # Calcular a matriz de confusão\n",
    "    confusion_matrix = np.zeros((3, 3), dtype=int)\n",
    "    for i in range(len(y_test)):\n",
    "        confusion_matrix[y_test[i]][y_pred[i]] += 1\n",
    "    \n",
    "    # Armazenar os resultados\n",
    "    accuracies.append(accuracy)\n",
    "    confusion_matrices.append(confusion_matrix)\n",
    "\n",
    "# Exibir os resultados\n",
    "print(\"Mean Accuracy:\", np.mean(accuracies))\n",
    "print(\"Standard Deviation of Accuracy:\", np.std(accuracies))\n",
    "best_confusion_matrix_index = np.argmax(accuracies)\n",
    "best_confusion_matrix = confusion_matrices[best_confusion_matrix_index]\n",
    "print(\"Best Confusion Matrix:\")\n",
    "print(best_confusion_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
