{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "def load_vertebral_column_uci():\n",
    "    # URL do arquivo ZIP\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00212/vertebral_column_data.zip\"\n",
    "    # Caminho local para salvar o arquivo ZIP\n",
    "    zip_path = \"dados/vertebral_column_data.zip\"\n",
    "    # Caminho local para o arquivo de dados extraído\n",
    "    data_path = \"dados/column_3C.dat\"\n",
    "\n",
    "    # Baixar o arquivo ZIP se ainda não foi baixado\n",
    "    if not os.path.exists(zip_path):\n",
    "        r = requests.get(url)\n",
    "        with open(zip_path, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "\n",
    "    # Extrair o arquivo de dados do ZIP se ainda não foi extraído\n",
    "    if not os.path.exists(data_path):\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(\"dados\")\n",
    "\n",
    "    # Ler o arquivo de dados\n",
    "    column_names = ['pelvic_incidence', 'pelvic_tilt', 'lumbar_lordosis_angle', 'sacral_slope', 'pelvic_radius', 'degree_spondylolisthesis', 'class']\n",
    "    vertebral_data = pd.read_csv(data_path, header=None, sep=' ', names=column_names)\n",
    "    X = vertebral_data.iloc[:, :-1].values\n",
    "    y = vertebral_data.iloc[:, -1].replace({'DH': 0, 'SL': 1, 'NO': 2}).values\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def preprocess_data(X, y, test_size=0.2, random_state=42):\n",
    "    # Dividir os dados em conjuntos de treinamento e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Padronizar os conjuntos de treinamento e teste separadamente\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def train_knn(X_train, y_train, n_neighbors=5):\n",
    "    knn_classifier = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "    return knn_classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class DMC:\n",
    "    def __init__(self):\n",
    "        self.centroids = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.centroids = {}\n",
    "        labels = np.unique(y_train)\n",
    "        for label in labels:\n",
    "            self.centroids[label] = np.mean(X_train[y_train == label], axis=0)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_pred = []\n",
    "        for x in X_test:\n",
    "            min_distance = float('inf')\n",
    "            predicted_label = None\n",
    "            for label, centroid in self.centroids.items():\n",
    "                distance = np.linalg.norm(x - centroid)\n",
    "                if distance < min_distance:\n",
    "                    min_distance = distance\n",
    "                    predicted_label = label\n",
    "            y_pred.append(predicted_label)\n",
    "        return np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.class_probs = None\n",
    "        self.means = None\n",
    "        self.stds = None\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.class_probs = {}\n",
    "        self.means = {}\n",
    "        self.stds = {}\n",
    "        labels = np.unique(y_train)\n",
    "        for label in labels:\n",
    "            self.class_probs[label] = np.mean(y_train == label)\n",
    "            self.means[label] = np.mean(X_train[y_train == label], axis=0)\n",
    "            self.stds[label] = np.std(X_train[y_train == label], axis=0)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_pred = []\n",
    "        for x in X_test:\n",
    "            max_prob = float('-inf')\n",
    "            predicted_label = None\n",
    "            for label, prob in self.class_probs.items():\n",
    "                likelihood = np.sum(np.log((1 / (np.sqrt(2 * np.pi) * self.stds[label] + 1e-9)) * np.exp(-((x - self.means[label]) ** 2) / (2 * ((self.stds[label] + 1e-9) ** 2)))))\n",
    "                posterior = np.log(prob) + likelihood\n",
    "                if posterior > max_prob:\n",
    "                    max_prob = posterior\n",
    "                    predicted_label = label\n",
    "            y_pred.append(predicted_label)\n",
    "        return np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gleilsonpedro\\AppData\\Local\\Temp\\ipykernel_10972\\1315638632.py:35: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  y = vertebral_data.iloc[:, -1].replace({'DH': 0, 'SL': 1, 'NO': 2}).values\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'NearestCentroid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 94\u001b[0m\n\u001b[0;32m     91\u001b[0m X, y \u001b[38;5;241m=\u001b[39m load_vertebral_column_uci()\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Executar o holdout\u001b[39;00m\n\u001b[1;32m---> 94\u001b[0m best_knn, best_dmc, best_nb \u001b[38;5;241m=\u001b[39m \u001b[43mholdout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMelhor acurácia para k-NN:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAcurácia máxima:\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_knn[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[1;32mIn[32], line 61\u001b[0m, in \u001b[0;36mholdout\u001b[1;34m(X, y, test_size, random_state, num_runs)\u001b[0m\n\u001b[0;32m     58\u001b[0m     best_accuracy_knn \u001b[38;5;241m=\u001b[39m accuracy_knn\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m# Treinamento e teste do DMC (Discriminante de Mínima Distância)\u001b[39;00m\n\u001b[1;32m---> 61\u001b[0m dmc \u001b[38;5;241m=\u001b[39m \u001b[43mNearestCentroid\u001b[49m()\n\u001b[0;32m     62\u001b[0m dmc\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     63\u001b[0m y_pred_dmc \u001b[38;5;241m=\u001b[39m dmc\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'NearestCentroid' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "\n",
    "# Função para carregar os dados do conjunto de dados vertebral column da UCI\n",
    "def load_vertebral_column_uci():\n",
    "    # URL do arquivo ZIP\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00212/vertebral_column_data.zip\"\n",
    "    # Caminho local para salvar o arquivo ZIP\n",
    "    zip_path = \"dados/vertebral_column_data.zip\"\n",
    "    # Caminho local para o arquivo de dados extraído\n",
    "    data_path = \"dados/column_3C.dat\"\n",
    "\n",
    "    # Baixar o arquivo ZIP se ainda não foi baixado\n",
    "    if not os.path.exists(zip_path):\n",
    "        r = requests.get(url)\n",
    "        with open(zip_path, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "\n",
    "    # Extrair o arquivo de dados do ZIP se ainda não foi extraído\n",
    "    if not os.path.exists(data_path):\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(\"dados\")\n",
    "\n",
    "    # Ler o arquivo de dados\n",
    "    column_names = ['pelvic_incidence', 'pelvic_tilt', 'lumbar_lordosis_angle', 'sacral_slope', 'pelvic_radius', 'degree_spondylolisthesis', 'class']\n",
    "    vertebral_data = pd.read_csv(data_path, header=None, sep=' ', names=column_names)\n",
    "    X = vertebral_data.iloc[:, :-1].values\n",
    "    y = vertebral_data.iloc[:, -1].replace({'DH': 0, 'SL': 1, 'NO': 2}).values\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# Função para dividir os dados em treino e teste e executar o holdout com 20 realizações\n",
    "def holdout(X, y, test_size=0.3, random_state=42, num_runs=20):\n",
    "    best_accuracy_knn = -1\n",
    "    best_accuracy_dmc = -1\n",
    "    best_accuracy_nb = -1\n",
    "    accuracies_knn = []\n",
    "    accuracies_dmc = []\n",
    "    accuracies_nb = []\n",
    "\n",
    "    for run in range(1, num_runs + 1):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "        # Treinamento e teste do k-NN\n",
    "        knn = KNeighborsClassifier()\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred_knn = knn.predict(X_test)\n",
    "        accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "        accuracies_knn.append(accuracy_knn)\n",
    "        if accuracy_knn > best_accuracy_knn:\n",
    "            best_accuracy_knn = accuracy_knn\n",
    "\n",
    "        # Treinamento e teste do DMC (Discriminante de Mínima Distância)\n",
    "        dmc = NearestCentroid()\n",
    "        dmc.fit(X_train, y_train)\n",
    "        y_pred_dmc = dmc.predict(X_test)\n",
    "        accuracy_dmc = accuracy_score(y_test, y_pred_dmc)\n",
    "        accuracies_dmc.append(accuracy_dmc)\n",
    "        if accuracy_dmc > best_accuracy_dmc:\n",
    "            best_accuracy_dmc = accuracy_dmc\n",
    "\n",
    "        # Treinamento e teste do Naive Bayes\n",
    "        nb = GaussianNB()\n",
    "        nb.fit(X_train, y_train)\n",
    "        y_pred_nb = nb.predict(X_test)\n",
    "        accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
    "        accuracies_nb.append(accuracy_nb)\n",
    "        if accuracy_nb > best_accuracy_nb:\n",
    "            best_accuracy_nb = accuracy_nb\n",
    "\n",
    "    # Calcula a média e o desvio padrão das acurácias para cada classificador\n",
    "    mean_accuracy_knn = np.mean(accuracies_knn)\n",
    "    std_accuracy_knn = np.std(accuracies_knn)\n",
    "    mean_accuracy_dmc = np.mean(accuracies_dmc)\n",
    "    std_accuracy_dmc = np.std(accuracies_dmc)\n",
    "    mean_accuracy_nb = np.mean(accuracies_nb)\n",
    "    std_accuracy_nb = np.std(accuracies_nb)\n",
    "\n",
    "    return (best_accuracy_knn, mean_accuracy_knn, std_accuracy_knn), \\\n",
    "           (best_accuracy_dmc, mean_accuracy_dmc, std_accuracy_dmc), \\\n",
    "           (best_accuracy_nb, mean_accuracy_nb, std_accuracy_nb)\n",
    "\n",
    "# Carregar os dados\n",
    "X, y = load_vertebral_column_uci()\n",
    "\n",
    "# Executar o holdout\n",
    "best_knn, best_dmc, best_nb = holdout(X, y)\n",
    "\n",
    "print(\"Melhor acurácia para k-NN:\")\n",
    "print(\"Acurácia máxima:\", best_knn[0])\n",
    "print(\"Média das acurácias:\", best_knn[1])\n",
    "print(\"Desvio padrão das acurácias:\", best_knn[2])\n",
    "\n",
    "print(\"\\nMelhor acurácia para DMC:\")\n",
    "print(\"Acurácia máxima:\", best_dmc[0])\n",
    "print(\"Média das acurácias:\", best_dmc[1])\n",
    "print(\"Desvio padrão das acurácias:\", best_dmc[2])\n",
    "\n",
    "print(\"\\nMelhor acurácia para Naive Bayes:\")\n",
    "print(\"Acurácia máxima:\", best_nb[0])\n",
    "print(\"Média das acurácias:\", best_nb[1])\n",
    "print(\"Desvio padrão das acurácias:\", best_nb[2])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
